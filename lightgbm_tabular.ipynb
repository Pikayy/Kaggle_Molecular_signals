{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "393bca0e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-10-20T10:38:02.528945Z",
     "iopub.status.busy": "2021-10-20T10:38:02.528584Z",
     "iopub.status.idle": "2021-10-20T10:38:02.546433Z",
     "shell.execute_reply": "2021-10-20T10:38:02.545786Z",
     "shell.execute_reply.started": "2021-10-20T10:38:02.528849Z"
    },
    "papermill": {
     "duration": 0.025731,
     "end_time": "2021-10-29T21:46:18.648727",
     "exception": false,
     "start_time": "2021-10-29T21:46:18.622996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Time to stimulate the thought processes.\n",
    "\n",
    "\n",
    "There is NO NEW code here. You've seen similar code many times.\n",
    "I expect that the vast majority of which has been better written.\n",
    "\n",
    "My thoughts are scattered around the notebook. Again you generally probably see (or have) better ones. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954c87f",
   "metadata": {
    "papermill": {
     "duration": 0.021385,
     "end_time": "2021-10-29T21:46:18.692244",
     "exception": false,
     "start_time": "2021-10-29T21:46:18.670859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Results tracking\n",
    "\n",
    "V3  LGBM0 Overall Training Validation Score | Blend: 0.8569692225223414 with LB score of 0.85633\n",
    "\n",
    "V4  LGBM0 Overall Training Validation Score | Blend: 0.8570320102774184 with LB score of 0.85623\n",
    "\n",
    "V5  LGBM0 Overall Training Validation Score | Blend: 0.8570190414332162 with LB score of 0.85627\n",
    "\n",
    "V6  LGBM1 Overall Training Validation Score | Blend: 0.8571127311293687 with LB score of 0.85633\n",
    "\n",
    "V7   XGB0 Overall Training Validation Score | Blend: 0.8570048237818386 with LB score of 0.85645\n",
    "\n",
    "V8   XGB1 Overall Training Validation Score | Blend: 0.8568621253215738 with LB score of 0.85621\n",
    "\n",
    "V10 CATB0 Overall Training Validation Score | Blend: 0.8566436011399643 with LB score of 0.85597\n",
    "\n",
    "V11 LGBM0 Overall Training Validation Score | Blend: 0.8569640619014858 with LB score of 0.85638\n",
    "\n",
    "V12 LGBM0 Overall Training Validation Score | Blend: 0.8569158481801216 with LB score of 0.85639\n",
    "\n",
    "\n",
    "\n",
    "Recap of version 12\n",
    "That v11 vs v12 is starting to annoy me.\n",
    "Let me double check my changes. Boolean features where changed to type 'category'. \n",
    "Boolean features where removed from Scaler. (another Q.  what happens to type catgeory within a scaler?)\n",
    "Boolean features where listed as such within the params (another Q. is that not default for the datatype?)\n",
    "So really simple changes and the CV score decreases by 5 times as much as the LB increases.\n",
    "Ignoring the LB side of the problem doesn't help becuase I can't explain the CV side to start with.\n",
    "And I really don't want to trawl through LGB source code to search for an answer. \n",
    "Always that same darn riddle. Do you trust LB or CV?\n",
    "\n",
    "\n",
    "I'll need to go read ROC notebooks again :(\n",
    "Wasted my time. It seems that is hasn't changed in ages. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd52d190",
   "metadata": {
    "papermill": {
     "duration": 0.022018,
     "end_time": "2021-10-29T21:46:18.735843",
     "exception": false,
     "start_time": "2021-10-29T21:46:18.713825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Onto Version 13.\n",
    "\n",
    "So some really difficult situations as I want one and only one LGBM model.\n",
    "Which is the right one to choose.\n",
    "\n",
    "\n",
    "I'm going to choose V11 as I trust CV but obviously the reader can do whatever they want with whatever they may have to hand. Also I forgot to add v12 to the dataset.\n",
    "I'm too lazy to add it now. You know where it is if you really want it.\n",
    "But yes - notice I added a new dataset which should be public. This is a dataset containing the key oof and submission data that this notebook has generated. \n",
    "So it was effectively public already. I've just colleced and centralised it.\n",
    "\n",
    "\n",
    "Only a couple days left and this notebook is about 20th on the list of public notebooks. An improvment of 0.0003 would put it in 1st place or public notebooks. \n",
    "It would also move it into top 30-100 of the real LB. I wonder how many of those tied for 30th have teh exact same copied code.\n",
    "\n",
    "This gives us something to aim for as the vast majority of better scoring code is generally just blending and lets be honest: If your code runs in less that 20 seconds it probably isn't going to be that original.\n",
    "\n",
    "I'm keen to try some ensemble with a twist. Too much of the standard stuff already published. In the past we sometimes tried adding a prediction set as a new feature and \n",
    "I'm going to give that a try today.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74f82b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:46:18.786235Z",
     "iopub.status.busy": "2021-10-29T21:46:18.784964Z",
     "iopub.status.idle": "2021-10-29T21:46:22.272020Z",
     "shell.execute_reply": "2021-10-29T21:46:22.272834Z",
     "shell.execute_reply.started": "2021-10-29T21:39:59.501647Z"
    },
    "papermill": {
     "duration": 3.513843,
     "end_time": "2021-10-29T21:46:22.273320",
     "exception": false,
     "start_time": "2021-10-29T21:46:18.759477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import json\n",
    "import optuna\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import optuna.integration.lightgbm as lgbo\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datatable as dt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "from warnings import resetwarnings\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "## Better check what version we are using as I may want to make use of init_model\n",
    "import lightgbm as lgbm\n",
    "print (lgbm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8a6738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:46:22.335895Z",
     "iopub.status.busy": "2021-10-29T21:46:22.335123Z",
     "iopub.status.idle": "2021-10-29T21:46:22.338311Z",
     "shell.execute_reply": "2021-10-29T21:46:22.337662Z",
     "shell.execute_reply.started": "2021-10-29T21:40:02.785864Z"
    },
    "papermill": {
     "duration": 0.042562,
     "end_time": "2021-10-29T21:46:22.338458",
     "exception": false,
     "start_time": "2021-10-29T21:46:22.295896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if (\n",
    "                    c_min > np.finfo(np.float16).min\n",
    "                    and c_max < np.finfo(np.float16).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif (\n",
    "                    c_min > np.finfo(np.float32).min\n",
    "                    and c_max < np.finfo(np.float32).max\n",
    "                ):\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    if verbose:\n",
    "        print(\n",
    "            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n",
    "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
    "            )\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072f35e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:46:22.386738Z",
     "iopub.status.busy": "2021-10-29T21:46:22.385769Z",
     "iopub.status.idle": "2021-10-29T21:49:22.710894Z",
     "shell.execute_reply": "2021-10-29T21:49:22.711817Z",
     "shell.execute_reply.started": "2021-10-29T21:40:02.802577Z"
    },
    "papermill": {
     "duration": 180.351584,
     "end_time": "2021-10-29T21:49:22.712134",
     "exception": false,
     "start_time": "2021-10-29T21:46:22.360550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 505.45 Mb (73.1% reduction)\n",
      "Mem. usage decreased to 252.25 Mb (73.1% reduction)\n",
      "CPU times: user 1min 28s, sys: 1min 38s, total: 3min 7s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_train = reduce_mem_usage(dt.fread('../input/tabular-playground-series-oct-2021/train.csv').to_pandas())\n",
    "df_test = reduce_mem_usage (dt.fread('../input/tabular-playground-series-oct-2021/test.csv').to_pandas())\n",
    "\n",
    "sample_submission = pd.read_csv(\"../input/tabular-playground-series-oct-2021/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b354589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:49:22.774232Z",
     "iopub.status.busy": "2021-10-29T21:49:22.773151Z",
     "iopub.status.idle": "2021-10-29T21:49:22.775040Z",
     "shell.execute_reply": "2021-10-29T21:49:22.775571Z",
     "shell.execute_reply.started": "2021-10-29T21:42:04.774670Z"
    },
    "papermill": {
     "duration": 0.034249,
     "end_time": "2021-10-29T21:49:22.775776",
     "exception": false,
     "start_time": "2021-10-29T21:49:22.741527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Always handy to know how many features we are dealing with\n",
    "num_cols = [col for col in df_test.columns]  ## remember that this will include id which isn't really a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cebd37c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:49:22.829325Z",
     "iopub.status.busy": "2021-10-29T21:49:22.828241Z",
     "iopub.status.idle": "2021-10-29T21:49:25.018060Z",
     "shell.execute_reply": "2021-10-29T21:49:25.018650Z",
     "shell.execute_reply.started": "2021-10-29T21:42:04.781805Z"
    },
    "papermill": {
     "duration": 2.219115,
     "end_time": "2021-10-29T21:49:25.018853",
     "exception": false,
     "start_time": "2021-10-29T21:49:22.799738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare dataframe for modeling\n",
    "X = df_train.drop(columns=[\"id\", \"target\"]).copy()\n",
    "y = df_train[\"target\"].copy()\n",
    "\n",
    "test_data = df_test.drop(columns=[\"id\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a2f53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:49:25.072196Z",
     "iopub.status.busy": "2021-10-29T21:49:25.071339Z",
     "iopub.status.idle": "2021-10-29T21:49:33.550548Z",
     "shell.execute_reply": "2021-10-29T21:49:33.549923Z",
     "shell.execute_reply.started": "2021-10-29T21:42:06.498325Z"
    },
    "papermill": {
     "duration": 8.509051,
     "end_time": "2021-10-29T21:49:33.550732",
     "exception": false,
     "start_time": "2021-10-29T21:49:25.041681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_cols = X.columns[(X.nunique() < 5)]\n",
    "con_cols = X.columns[(X.nunique() >= 5)]\n",
    "cat_cols_indices = [X.columns.get_loc(col) for col in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f1fab27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:49:33.601929Z",
     "iopub.status.busy": "2021-10-29T21:49:33.600229Z",
     "iopub.status.idle": "2021-10-29T21:49:33.607545Z",
     "shell.execute_reply": "2021-10-29T21:49:33.606654Z",
     "shell.execute_reply.started": "2021-10-29T21:42:15.282712Z"
    },
    "papermill": {
     "duration": 0.03363,
     "end_time": "2021-10-29T21:49:33.607748",
     "exception": false,
     "start_time": "2021-10-29T21:49:33.574118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_pred = pd.DataFrame(np.zeros(df_train.shape[0]), columns = ['pred'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5be65c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:49:33.864905Z",
     "iopub.status.busy": "2021-10-29T21:49:33.863870Z",
     "iopub.status.idle": "2021-10-29T21:49:33.867632Z",
     "shell.execute_reply": "2021-10-29T21:49:33.868173Z",
     "shell.execute_reply.started": "2021-10-29T21:42:15.289981Z"
    },
    "papermill": {
     "duration": 0.237021,
     "end_time": "2021-10-29T21:49:33.868401",
     "exception": false,
     "start_time": "2021-10-29T21:49:33.631380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "del df_test, df_train\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d854116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:49:33.920417Z",
     "iopub.status.busy": "2021-10-29T21:49:33.919378Z",
     "iopub.status.idle": "2021-10-29T21:50:08.351815Z",
     "shell.execute_reply": "2021-10-29T21:50:08.352429Z",
     "shell.execute_reply.started": "2021-10-29T21:42:15.445799Z"
    },
    "papermill": {
     "duration": 34.460937,
     "end_time": "2021-10-29T21:50:08.352647",
     "exception": false,
     "start_time": "2021-10-29T21:49:33.891710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 457.76 Mb (0.0% reduction)\n",
      "Mem. usage decreased to 228.88 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X[con_cols] = reduce_mem_usage(pd.DataFrame(columns=con_cols, data=scaler.fit_transform(X[con_cols])))\n",
    "test_data[con_cols] = reduce_mem_usage(pd.DataFrame(columns=con_cols, data=scaler.transform(test_data[con_cols])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3801c0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:50:08.411497Z",
     "iopub.status.busy": "2021-10-29T21:50:08.405816Z",
     "iopub.status.idle": "2021-10-29T21:50:08.415147Z",
     "shell.execute_reply": "2021-10-29T21:50:08.415706Z",
     "shell.execute_reply.started": "2021-10-29T21:42:48.220514Z"
    },
    "papermill": {
     "duration": 0.039333,
     "end_time": "2021-10-29T21:50:08.415925",
     "exception": false,
     "start_time": "2021-10-29T21:50:08.376592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hopefully there is nothing new above this line\n",
    "def load_sp_data():\n",
    "    df_train_tmp = pd.read_csv(\"../input/sandpit-data/v6_f_pred_train.csv\")\n",
    "    df_test_tmp = pd.read_csv(\"../input/sandpit-data/v6_f_pred_test.csv\")\n",
    "    X['v6']  = df_train_tmp['pred']\n",
    "    test_data['v6'] = df_test_tmp['pred']\n",
    "\n",
    "    df_train_tmp = pd.read_csv(\"../input/sandpit-data/v7_f_pred_train.csv\")\n",
    "    df_test_tmp = pd.read_csv(\"../input/sandpit-data/v7_f_pred_test.csv\")\n",
    "    X['v7']  = df_train_tmp['pred']\n",
    "    test_data['v7'] = df_test_tmp['pred']\n",
    "    \n",
    "    df_train_tmp = pd.read_csv(\"../input/sandpit-data/v8_f_pred_train.csv\")\n",
    "    df_test_tmp = pd.read_csv(\"../input/sandpit-data/v8_f_pred_test.csv\")\n",
    "    X['v8']  = df_train_tmp['pred']\n",
    "    test_data['v8'] = df_test_tmp['pred']\n",
    "    \n",
    "    df_train_tmp = pd.read_csv(\"../input/sandpit-data/v10_f_pred_train.csv\")\n",
    "    df_test_tmp = pd.read_csv(\"../input/sandpit-data/v10_f_pred_test.csv\")\n",
    "    X['v10']  = df_train_tmp['pred']\n",
    "    test_data['v10'] = df_test_tmp['pred']\n",
    "    \n",
    "    df_train_tmp = pd.read_csv(\"../input/sandpit-data/v11_f_pred_train.csv\")\n",
    "    df_test_tmp = pd.read_csv(\"../input/sandpit-data/v11_f_pred_test.csv\")\n",
    "    X['v11']  = df_train_tmp['pred']\n",
    "    test_data['v11'] = df_test_tmp['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f144f849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:50:08.467928Z",
     "iopub.status.busy": "2021-10-29T21:50:08.467208Z",
     "iopub.status.idle": "2021-10-29T21:50:21.831700Z",
     "shell.execute_reply": "2021-10-29T21:50:21.832245Z",
     "shell.execute_reply.started": "2021-10-29T21:42:48.231134Z"
    },
    "papermill": {
     "duration": 13.392208,
     "end_time": "2021-10-29T21:50:21.832478",
     "exception": false,
     "start_time": "2021-10-29T21:50:08.440270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              v6        v7        v8       v10       v11       v12\n",
      "0       0.636330  0.627991  0.619686  0.590088  0.644283  0.630680\n",
      "1       0.163295  0.204292  0.184968  0.161027  0.177315  0.173058\n",
      "2       0.838665  0.842159  0.835375  0.848305  0.833164  0.829121\n",
      "3       0.499721  0.509823  0.515439  0.477536  0.532462  0.505442\n",
      "4       0.824956  0.847930  0.821259  0.826900  0.834583  0.819997\n",
      "...          ...       ...       ...       ...       ...       ...\n",
      "999995  0.764122  0.705724  0.756485  0.820989  0.764636  0.735261\n",
      "999996  0.126830  0.121882  0.098413  0.133618  0.122352  0.129075\n",
      "999997  0.178504  0.179142  0.163010  0.172238  0.175019  0.173877\n",
      "999998  0.914509  0.912751  0.923301  0.899962  0.900747  0.910514\n",
      "999999  0.610694  0.584213  0.571907  0.582276  0.579980  0.584852\n",
      "\n",
      "[1000000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "load_sp_data ()\n",
    "# As I run this I realise that maybe I could just grap v12 now as I have also included the dataset of this notebook. So I have access to anything in last saved version\n",
    "\n",
    "df_train_tmp = pd.read_csv(\"../input/tps-oct-joes-sandpit/f_pred_train.csv\" )\n",
    "df_test_tmp = pd.read_csv(\"../input/tps-oct-joes-sandpit/f_pred_test.csv\")\n",
    "X['v12']  = df_train_tmp['pred']\n",
    "test_data['v12'] = df_test_tmp['pred']\n",
    "\n",
    "### Just in case I want it again ... in next run.\n",
    "df_train_tmp.to_csv(\"./f_pred_train_12.csv\", index=True)\n",
    "df_test_tmp.to_csv(\"./f_pred_test_12.csv\", index=True)\n",
    "\n",
    "\n",
    "f_pred_cols = ['v6', 'v7', 'v8', 'v10', 'v11', \"v12\" ]\n",
    "print (X[f_pred_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05734872",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:50:21.889946Z",
     "iopub.status.busy": "2021-10-29T21:50:21.888986Z",
     "iopub.status.idle": "2021-10-29T21:50:23.378706Z",
     "shell.execute_reply": "2021-10-29T21:50:23.379228Z",
     "shell.execute_reply.started": "2021-10-29T21:43:00.847027Z"
    },
    "papermill": {
     "duration": 1.522886,
     "end_time": "2021-10-29T21:50:23.379474",
     "exception": false,
     "start_time": "2021-10-29T21:50:21.856588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              f0        f1        f2        f3        f4        f5        f6  \\\n",
      "0      -0.157593 -0.486816  0.393311 -0.854004 -1.362305  1.020508  0.202637   \n",
      "1      -0.624512  0.127563 -0.972656 -1.012695  0.337402  0.429688 -1.169922   \n",
      "2      -0.594727 -1.508789  1.627930 -1.115234  0.214722 -1.833984  0.800781   \n",
      "3      -0.638184  0.339844 -1.000977 -0.854004  1.561523  0.387695  0.341553   \n",
      "4      -0.697754  0.349365 -0.951660  4.292969  0.388184  2.505859 -2.017578   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "999995 -0.187378 -1.139648  1.100586 -0.778809  0.261230 -1.016602  0.778809   \n",
      "999996 -0.605957  1.024414  0.937500 -0.575684 -1.101562  0.907715  0.682129   \n",
      "999997  0.673828  0.308350 -0.253906 -0.665039  1.654297 -0.836426  1.088867   \n",
      "999998 -0.201050  0.739746  0.421631 -1.020508  0.642578  2.035156 -0.527344   \n",
      "999999 -1.000000  1.341797 -0.961914  0.042358 -0.005482 -0.253418  0.804688   \n",
      "\n",
      "              f7        f8        f9  ...   f278   f279   f280   f281   f282  \\\n",
      "0      -0.660645  0.559082 -0.929688  ...  False  False  False  False  False   \n",
      "1       0.478516 -1.392578 -0.163696  ...  False  False  False  False  False   \n",
      "2       1.475586  0.570312  0.242188  ...  False   True   True  False  False   \n",
      "3       1.865234  0.167114  0.024826  ...  False  False   True  False  False   \n",
      "4      -1.439453 -2.976562 -0.837402  ...   True  False   True  False  False   \n",
      "...          ...       ...       ...  ...    ...    ...    ...    ...    ...   \n",
      "999995 -0.630371  0.363281 -0.815918  ...  False   True  False  False   True   \n",
      "999996  0.066345  0.438721 -0.044891  ...  False  False  False  False  False   \n",
      "999997 -0.870117  1.208008  0.766602  ...  False  False  False  False  False   \n",
      "999998 -0.038574 -0.497070 -0.048981  ...  False  False  False  False  False   \n",
      "999999 -0.660645  0.532715  0.094482  ...  False  False  False  False  False   \n",
      "\n",
      "         f283   f284        v7       v10       v11  \n",
      "0       False  False  0.627991  0.590088  0.644283  \n",
      "1       False  False  0.204292  0.161027  0.177315  \n",
      "2       False  False  0.842159  0.848305  0.833164  \n",
      "3       False  False  0.509823  0.477536  0.532462  \n",
      "4        True  False  0.847930  0.826900  0.834583  \n",
      "...       ...    ...       ...       ...       ...  \n",
      "999995  False  False  0.705724  0.820989  0.764636  \n",
      "999996  False   True  0.121882  0.133618  0.122352  \n",
      "999997  False  False  0.179142  0.172238  0.175019  \n",
      "999998  False  False  0.912751  0.899962  0.900747  \n",
      "999999  False  False  0.584213  0.582276  0.579980  \n",
      "\n",
      "[1000000 rows x 288 columns]\n"
     ]
    }
   ],
   "source": [
    "# okay that looks decent but I forgot what we are dealing with. \n",
    "# From the header - I get the details\n",
    "# V6 LGBM1 Overall Training Validation Score | Blend: 0.8571127311293687 with LB score of 0.85633\n",
    "# V7 XGB0 Overall Training Validation Score | Blend: 0.8570048237818386 with LB score of 0.85645\n",
    "# V8 XGB1 Overall Training Validation Score | Blend: 0.8568621253215738 with LB score of 0.85621\n",
    "# V10 CATB0 Overall Training Validation Score | Blend: 0.8566436011399643 with LB score of 0.85597\n",
    "# V11 LGBM0 Overall Training Validation Score | Blend: 0.8569640619014858 with LB score of 0.85638\n",
    "# V12 LGBM0 Overall Training Validation Score | Blend: 0.8569158481801216 with LB score of 0.85639\n",
    "\n",
    "# I want one of each type so will definetly use v10\n",
    "# Then I will add v11 for my lgb choice and v7 for my xgb choice\n",
    "# So (double check) I should drop v6, v8, v12\n",
    "\n",
    "# V10 is not a great model. Hopefully not my doing and rather a 'function' of catboost on the gien dataset.\n",
    "# Should we include V10 or will it just be noise. Add FI later to check\n",
    "\n",
    "X = X.drop(columns=[\"v6\", \"v8\", \"v12\"])\n",
    "\n",
    "### apparently you can get much further into the notebook before it reminds you to do something simialr to test :(\n",
    "test_data = test_data.drop(columns=[\"v6\", \"v8\", \"v12\"])\n",
    "\n",
    "\n",
    "###\n",
    "### What happens if we don't drop them and use all 6 new features ?\n",
    "### What happens if we add another 10 such new features ?\n",
    "### Well that always depends. I tend to think as computers of being able to use every last bit of data but there are always cases that it doens't work in your favour.\n",
    "### For this partcular case .... I don't know, I haven't tried. \n",
    "\n",
    "### But I am 95% sure that theh winner of this comp will have used more that one model and most probably lots of models!\n",
    "\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "980280ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:50:23.434475Z",
     "iopub.status.busy": "2021-10-29T21:50:23.433455Z",
     "iopub.status.idle": "2021-10-29T21:50:23.648223Z",
     "shell.execute_reply": "2021-10-29T21:50:23.647614Z",
     "shell.execute_reply.started": "2021-10-29T21:43:01.507189Z"
    },
    "papermill": {
     "duration": 0.243588,
     "end_time": "2021-10-29T21:50:23.648444",
     "exception": false,
     "start_time": "2021-10-29T21:50:23.404856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del scaler\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb94cab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:50:23.710207Z",
     "iopub.status.busy": "2021-10-29T21:50:23.709415Z",
     "iopub.status.idle": "2021-10-29T21:50:23.720511Z",
     "shell.execute_reply": "2021-10-29T21:50:23.719917Z",
     "shell.execute_reply.started": "2021-10-29T21:43:01.648607Z"
    },
    "papermill": {
     "duration": 0.046729,
     "end_time": "2021-10-29T21:50:23.720692",
     "exception": false,
     "start_time": "2021-10-29T21:50:23.673963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I still need to find where I got these params from and the try and credit the source\n",
    "lgbm_params_0 = {\n",
    "     'objective': 'binary',\n",
    "     'n_estimators':92700,        ## way to high but I have faith in early stopping criteria\n",
    "#      'importance_type': 'gain',\n",
    "     'metric':'auc',\n",
    "#      'boosting_type': 'gbdt',\n",
    "     'boosting_type': 'goss',\n",
    "     'n_jobs' : -1,\n",
    "    'learning_rate': 0.1, \n",
    "    'colsample_bytree': 0.3, \n",
    "    'reg_lambda': 0.011685550612519125, \n",
    "    'reg_alpha': 0.04502045156737212,\n",
    "#     Let the model know about the categorical features    \n",
    "#     'categorical_feature' : cat_features,\n",
    "#     'feature_name': 'auto',\n",
    "    'min_child_weight': 16.843316711276092, \n",
    "    'min_child_samples': 412, \n",
    "    'num_leaves': 546, \n",
    "    'max_depth': 5, \n",
    "    'cat_smooth': 36.40200359200525, \n",
    "    'cat_l2': 12.979520035205597\n",
    "    }\n",
    "\n",
    "# https://www.kaggle.com/vishwas21/tps-oct-21-eda-modeling\n",
    "# I'm not sure if that is the original source, but it is one of the earliest notebooks that mention these params\n",
    "xgb_params_0 = {\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 19500,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'colsample_bylevel': 0.6000000000000001,\n",
    "    'min_child_weight': 56.41980735551558,\n",
    "    'reg_lambda': 75.56651890088857,\n",
    "    'reg_alpha': 0.11766857055687065,\n",
    "    'gamma': 0.6407823221122686,\n",
    "    'booster': 'gbtree',\n",
    "    'eval_metric': 'auc',\n",
    "    'tree_method': 'hist',\n",
    "    'predictor': 'cpu_predictor',\n",
    "#     'tree_method': 'gpu_hist',\n",
    "#     'predictor': 'gpu_predictor',\n",
    "    'use_label_encoder': False\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "xgb_params_1 = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "#     \"learning_rate\": 8e-3,\n",
    "    \"learning_rate\": 0.016,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bylevel\": 0.9,\n",
    "    \"colsample_bytree\": 0.4,\n",
    "    \"n_estimators\": 20_000,\n",
    "    \"max_depth\": 8,\n",
    "    \"alpha\": 64,\n",
    "    \"lambda\": 32,\n",
    "    \"min_child_weight\": 8,\n",
    "    \"importance_type\": \"total_gain\",\n",
    "    \"tree_method\": \"hist\"#,\n",
    "#     \"predictor\": \"gpu_predictor\",\n",
    "}\n",
    "\n",
    "xgb_params_2 = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"tree_method\": \"hist\",\n",
    "#     \"learning_rate\": 0.02,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 20_000,\n",
    "    \"random_state\": 42,\n",
    "    \"lambda\": 0.003731399945310043,\n",
    "    \"alpha\": 0.1660536107526955,\n",
    "    \"colsample_bytree\": 0.5164889907489927,\n",
    "    \"subsample\": 0.5869840790716806,\n",
    "    \"max_depth\": 18,\n",
    "    \"min_child_weight\": 142}\n",
    "\n",
    "\n",
    "lgb_params = {'n_estimators': 20000,\n",
    "          'max_depth': 3,\n",
    "          'learning_rate': 0.003,\n",
    "          'reg_alpha': 9.5,\n",
    "          'reg_lambda': 8.5,\n",
    "          'num_leaves': 109,\n",
    "          'min_data_per_group': 133,\n",
    "          'min_child_samples': 113,\n",
    "          'colsample_bytree': 0.2,\n",
    "          'objective': 'binary',\n",
    "          'random_state': 2001,\n",
    "          'metric': 'auc',}\n",
    "\n",
    "\n",
    "\n",
    "# Taken from https://www.kaggle.com/dwoodlock/tps-oct2021-don#Modeling\n",
    "## he reckons around 0.85673 on average over 2 seeds\n",
    "lgbm_params_1 =  {\n",
    "    'objective' : 'binary',\n",
    "    'metric' : 'auc',\n",
    "    'num_leaves' : 7,\n",
    "#    'learning_rate' : 0.08,\n",
    "    'learning_rate' : 0.1,\n",
    "#     'device' : 'gpu',\n",
    "    'feature_pre_filter': False, \n",
    "    'reg_alpha': 9.314037635261775, \n",
    "    'reg_lambda': 0.10613573572440353,\n",
    "    'num_leaves': 7,\n",
    "    'colsample_bytree': 0.4, \n",
    "    'subsample': 0.8391963650875751, \n",
    "    'subsample_freq': 5, \n",
    "    'min_child_samples': 100,\n",
    "#     'num_iterations': trees, #10000,\n",
    "    'n_estimators': 60000\n",
    "}\n",
    "\n",
    "catb_params_0 = {\n",
    "    \"objective\": \"CrossEntropy\",\n",
    "    \"eval_metric\": \"AUC\",\n",
    "    \"grow_policy\": \"SymmetricTree\",\n",
    "    \"learning_rate\": 0.016,\n",
    "    \"n_estimators\": 30000,\n",
    "    \"random_strength\": 1.0,\n",
    "    \"max_bin\": 128,\n",
    "    \"l2_leaf_reg\": 0.002550319996478972,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_data_in_leaf\": 193,\n",
    "    \"random_state\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8d4c63f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:50:23.777763Z",
     "iopub.status.busy": "2021-10-29T21:50:23.776999Z",
     "iopub.status.idle": "2021-10-29T21:50:23.778474Z",
     "shell.execute_reply": "2021-10-29T21:50:23.778982Z",
     "shell.execute_reply.started": "2021-10-29T21:43:01.668713Z"
    },
    "papermill": {
     "duration": 0.032993,
     "end_time": "2021-10-29T21:50:23.779184",
     "exception": false,
     "start_time": "2021-10-29T21:50:23.746191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ### Now what do we choose for modelling.\n",
    "\n",
    "# I'm really hoping that the model I choose will \n",
    "# 1. Identify my new features as very important\n",
    "# 2. Spot instances of my new feature giving wrong results\n",
    "# 3. Magically identify (and rectify) some comibnation of factors that are common for records in 2.\n",
    "\n",
    "# As I think through the things that I want, I wonder if kmeans, generating new features at this stage would be the right way to go.\n",
    "# My kmeans attempt at https://www.kaggle.com/joecooper/experiment-with-kmeans certainly showed that it added value. \n",
    "# Recap - I used the predictions from sandpit to generate clusters (or cluster predictions) and then added those to the training data. \n",
    "# In this one I'm adding sandpit predictions directly to training data. I believe that (or maybe just hope) that the predictions\n",
    "# themselves will be more handy than a cluster feature they generate.\n",
    "\n",
    "# I think combining the 2 together might make task2 and 3 above a little easier for computer to solve. If it was a 2 month competition I would certainly look at that.\n",
    "# Actually if I had 1 spare day I would look at that. Don't think it would take long to check.\n",
    "\n",
    "# Anyway - I just randomly choose lgb first and lets see what happens.\n",
    "\n",
    "# I should also point out that I'm expecting FI to be significant for new features.\n",
    "# How will that change the gradient of each boost? \n",
    "# Certainly a different set of params might be MUCH better - but optuna takes time and I'm only hoping for a little bump up the leaderboard.\n",
    "\n",
    "# So I just choose another set of lgb params from public notebooks. \n",
    "# Not sure having the exact same set as a feature your trained on already is a good idea?\n",
    "# Again haven't tried, but my instinct say diversify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eba65be4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T21:50:23.833756Z",
     "iopub.status.busy": "2021-10-29T21:50:23.832966Z",
     "iopub.status.idle": "2021-10-29T23:44:13.895712Z",
     "shell.execute_reply": "2021-10-29T23:44:13.897191Z",
     "shell.execute_reply.started": "2021-10-29T21:43:01.685626Z"
    },
    "papermill": {
     "duration": 6830.093814,
     "end_time": "2021-10-29T23:44:13.898821",
     "exception": false,
     "start_time": "2021-10-29T21:50:23.805007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time : 2021-10-29 21:50:23.845427\n",
      "Fold :  0  Start :  2021-10-29 21:50:23.997863\n",
      "model name :  lgbm0  Start :  2021-10-29 21:50:24.864484\n",
      "Name starts with lgbm0\n",
      "Training until validation scores don't improve for 700 rounds\n",
      "[200]\tvalid_0's auc: 0.855272\n",
      "[400]\tvalid_0's auc: 0.855558\n",
      "[600]\tvalid_0's auc: 0.855736\n",
      "[800]\tvalid_0's auc: 0.855845\n",
      "[1000]\tvalid_0's auc: 0.855884\n",
      "[1200]\tvalid_0's auc: 0.855946\n",
      "[1400]\tvalid_0's auc: 0.85599\n",
      "[1600]\tvalid_0's auc: 0.855994\n",
      "[1800]\tvalid_0's auc: 0.855999\n",
      "[2000]\tvalid_0's auc: 0.856002\n",
      "[2200]\tvalid_0's auc: 0.856004\n",
      "[2400]\tvalid_0's auc: 0.856005\n",
      "[2600]\tvalid_0's auc: 0.856008\n",
      "[2800]\tvalid_0's auc: 0.856013\n",
      "[3000]\tvalid_0's auc: 0.856019\n",
      "[3200]\tvalid_0's auc: 0.856024\n",
      "[3400]\tvalid_0's auc: 0.856031\n",
      "[3600]\tvalid_0's auc: 0.856037\n",
      "[3800]\tvalid_0's auc: 0.856042\n",
      "[4000]\tvalid_0's auc: 0.856046\n",
      "[4200]\tvalid_0's auc: 0.856053\n",
      "[4400]\tvalid_0's auc: 0.856059\n",
      "[4600]\tvalid_0's auc: 0.856067\n",
      "[4800]\tvalid_0's auc: 0.856078\n",
      "[5000]\tvalid_0's auc: 0.856088\n",
      "[5200]\tvalid_0's auc: 0.856099\n",
      "[5400]\tvalid_0's auc: 0.85611\n",
      "[5600]\tvalid_0's auc: 0.856118\n",
      "[5800]\tvalid_0's auc: 0.856126\n",
      "[6000]\tvalid_0's auc: 0.856133\n",
      "[6200]\tvalid_0's auc: 0.856137\n",
      "[6400]\tvalid_0's auc: 0.856142\n",
      "[6600]\tvalid_0's auc: 0.856146\n",
      "[6800]\tvalid_0's auc: 0.856146\n",
      "[7000]\tvalid_0's auc: 0.856149\n",
      "[7200]\tvalid_0's auc: 0.856151\n",
      "[7400]\tvalid_0's auc: 0.856153\n",
      "[7600]\tvalid_0's auc: 0.856153\n",
      "[7800]\tvalid_0's auc: 0.856153\n",
      "[8000]\tvalid_0's auc: 0.856152\n",
      "Early stopping, best iteration is:\n",
      "[7489]\tvalid_0's auc: 0.856154\n",
      "Fold: 0 Model: lgbm0 Score: 0.8561540846553783 Duration : 0:18:12.174764\n",
      "Fold :  1  Start :  2021-10-29 22:10:56.783751\n",
      "model name :  lgbm0  Start :  2021-10-29 22:10:58.319931\n",
      "Name starts with lgbm0\n",
      "Training until validation scores don't improve for 700 rounds\n",
      "[200]\tvalid_0's auc: 0.856058\n",
      "[400]\tvalid_0's auc: 0.856366\n",
      "[600]\tvalid_0's auc: 0.85655\n",
      "[800]\tvalid_0's auc: 0.856687\n",
      "[1000]\tvalid_0's auc: 0.856781\n",
      "[1200]\tvalid_0's auc: 0.856866\n",
      "[1400]\tvalid_0's auc: 0.856914\n",
      "[1600]\tvalid_0's auc: 0.856932\n",
      "[1800]\tvalid_0's auc: 0.856946\n",
      "[2000]\tvalid_0's auc: 0.856957\n",
      "[2200]\tvalid_0's auc: 0.856966\n",
      "[2400]\tvalid_0's auc: 0.856972\n",
      "[2600]\tvalid_0's auc: 0.85698\n",
      "[2800]\tvalid_0's auc: 0.856988\n",
      "[3000]\tvalid_0's auc: 0.856995\n",
      "[3200]\tvalid_0's auc: 0.857005\n",
      "[3400]\tvalid_0's auc: 0.857012\n",
      "[3600]\tvalid_0's auc: 0.85702\n",
      "[3800]\tvalid_0's auc: 0.857026\n",
      "[4000]\tvalid_0's auc: 0.857032\n",
      "[4200]\tvalid_0's auc: 0.857039\n",
      "[4400]\tvalid_0's auc: 0.857047\n",
      "[4600]\tvalid_0's auc: 0.857055\n",
      "[4800]\tvalid_0's auc: 0.857065\n",
      "[5000]\tvalid_0's auc: 0.857077\n",
      "[5200]\tvalid_0's auc: 0.857086\n",
      "[5400]\tvalid_0's auc: 0.857097\n",
      "[5600]\tvalid_0's auc: 0.857107\n",
      "[5800]\tvalid_0's auc: 0.857115\n",
      "[6000]\tvalid_0's auc: 0.857123\n",
      "[6200]\tvalid_0's auc: 0.857128\n",
      "[6400]\tvalid_0's auc: 0.857133\n",
      "[6600]\tvalid_0's auc: 0.857138\n",
      "[6800]\tvalid_0's auc: 0.857139\n",
      "[7000]\tvalid_0's auc: 0.857142\n",
      "[7200]\tvalid_0's auc: 0.857145\n",
      "[7400]\tvalid_0's auc: 0.857146\n",
      "[7600]\tvalid_0's auc: 0.857147\n",
      "[7800]\tvalid_0's auc: 0.857149\n",
      "[8000]\tvalid_0's auc: 0.857148\n",
      "[8200]\tvalid_0's auc: 0.857148\n",
      "[8400]\tvalid_0's auc: 0.857146\n",
      "Early stopping, best iteration is:\n",
      "[7787]\tvalid_0's auc: 0.857149\n",
      "Fold: 1 Model: lgbm0 Score: 0.8571493113917871 Duration : 0:21:13.063921\n",
      "Fold :  2  Start :  2021-10-29 22:34:40.990036\n",
      "model name :  lgbm0  Start :  2021-10-29 22:34:42.144695\n",
      "Name starts with lgbm0\n",
      "Training until validation scores don't improve for 700 rounds\n",
      "[200]\tvalid_0's auc: 0.854952\n",
      "[400]\tvalid_0's auc: 0.855341\n",
      "[600]\tvalid_0's auc: 0.855487\n",
      "[800]\tvalid_0's auc: 0.855591\n",
      "[1000]\tvalid_0's auc: 0.855649\n",
      "[1200]\tvalid_0's auc: 0.855712\n",
      "[1400]\tvalid_0's auc: 0.855754\n",
      "[1600]\tvalid_0's auc: 0.855766\n",
      "[1800]\tvalid_0's auc: 0.855777\n",
      "[2000]\tvalid_0's auc: 0.855784\n",
      "[2200]\tvalid_0's auc: 0.855789\n",
      "[2400]\tvalid_0's auc: 0.855794\n",
      "[2600]\tvalid_0's auc: 0.8558\n",
      "[2800]\tvalid_0's auc: 0.855807\n",
      "[3000]\tvalid_0's auc: 0.855812\n",
      "[3200]\tvalid_0's auc: 0.855819\n",
      "[3400]\tvalid_0's auc: 0.855825\n",
      "[3600]\tvalid_0's auc: 0.855831\n",
      "[3800]\tvalid_0's auc: 0.855837\n",
      "[4000]\tvalid_0's auc: 0.855841\n",
      "[4200]\tvalid_0's auc: 0.855847\n",
      "[4400]\tvalid_0's auc: 0.855852\n",
      "[4600]\tvalid_0's auc: 0.855858\n",
      "[4800]\tvalid_0's auc: 0.855866\n",
      "[5000]\tvalid_0's auc: 0.855872\n",
      "[5200]\tvalid_0's auc: 0.855877\n",
      "[5400]\tvalid_0's auc: 0.855884\n",
      "[5600]\tvalid_0's auc: 0.855888\n",
      "[5800]\tvalid_0's auc: 0.855893\n",
      "[6000]\tvalid_0's auc: 0.855895\n",
      "[6200]\tvalid_0's auc: 0.855895\n",
      "[6400]\tvalid_0's auc: 0.855897\n",
      "[6600]\tvalid_0's auc: 0.855898\n",
      "[6800]\tvalid_0's auc: 0.855897\n",
      "[7000]\tvalid_0's auc: 0.855898\n",
      "[7200]\tvalid_0's auc: 0.855897\n",
      "Early stopping, best iteration is:\n",
      "[6608]\tvalid_0's auc: 0.855898\n",
      "Fold: 2 Model: lgbm0 Score: 0.8558984679148685 Duration : 0:18:15.459562\n",
      "Fold :  3  Start :  2021-10-29 22:55:05.597728\n",
      "model name :  lgbm0  Start :  2021-10-29 22:55:07.099489\n",
      "Name starts with lgbm0\n",
      "Training until validation scores don't improve for 700 rounds\n",
      "[200]\tvalid_0's auc: 0.857629\n",
      "[400]\tvalid_0's auc: 0.857925\n",
      "[600]\tvalid_0's auc: 0.858063\n",
      "[800]\tvalid_0's auc: 0.858194\n",
      "[1000]\tvalid_0's auc: 0.858262\n",
      "[1200]\tvalid_0's auc: 0.858329\n",
      "[1400]\tvalid_0's auc: 0.858374\n",
      "[1600]\tvalid_0's auc: 0.858394\n",
      "[1800]\tvalid_0's auc: 0.858409\n",
      "[2000]\tvalid_0's auc: 0.858426\n",
      "[2200]\tvalid_0's auc: 0.858436\n",
      "[2400]\tvalid_0's auc: 0.858444\n",
      "[2600]\tvalid_0's auc: 0.858452\n",
      "[2800]\tvalid_0's auc: 0.858462\n",
      "[3000]\tvalid_0's auc: 0.85847\n",
      "[3200]\tvalid_0's auc: 0.858479\n",
      "[3400]\tvalid_0's auc: 0.858487\n",
      "[3600]\tvalid_0's auc: 0.858496\n",
      "[3800]\tvalid_0's auc: 0.858504\n",
      "[4000]\tvalid_0's auc: 0.858512\n",
      "[4200]\tvalid_0's auc: 0.858522\n",
      "[4400]\tvalid_0's auc: 0.85853\n",
      "[4600]\tvalid_0's auc: 0.858537\n",
      "[4800]\tvalid_0's auc: 0.858548\n",
      "[5000]\tvalid_0's auc: 0.858558\n",
      "[5200]\tvalid_0's auc: 0.858567\n",
      "[5400]\tvalid_0's auc: 0.858577\n",
      "[5600]\tvalid_0's auc: 0.858585\n",
      "[5800]\tvalid_0's auc: 0.858591\n",
      "[6000]\tvalid_0's auc: 0.858598\n",
      "[6200]\tvalid_0's auc: 0.858602\n",
      "[6400]\tvalid_0's auc: 0.858606\n",
      "[6600]\tvalid_0's auc: 0.858611\n",
      "[6800]\tvalid_0's auc: 0.858614\n",
      "[7000]\tvalid_0's auc: 0.858616\n",
      "[7200]\tvalid_0's auc: 0.858617\n",
      "[7400]\tvalid_0's auc: 0.858619\n",
      "[7600]\tvalid_0's auc: 0.858619\n",
      "[7800]\tvalid_0's auc: 0.858619\n",
      "[8000]\tvalid_0's auc: 0.858617\n",
      "[8200]\tvalid_0's auc: 0.858616\n",
      "Early stopping, best iteration is:\n",
      "[7553]\tvalid_0's auc: 0.85862\n",
      "Fold: 3 Model: lgbm0 Score: 0.8586197052752808 Duration : 0:20:31.870354\n",
      "Fold :  4  Start :  2021-10-29 23:18:16.353376\n",
      "model name :  lgbm0  Start :  2021-10-29 23:18:17.793343\n",
      "Name starts with lgbm0\n",
      "Training until validation scores don't improve for 700 rounds\n",
      "[200]\tvalid_0's auc: 0.856455\n",
      "[400]\tvalid_0's auc: 0.856679\n",
      "[600]\tvalid_0's auc: 0.856885\n",
      "[800]\tvalid_0's auc: 0.857034\n",
      "[1000]\tvalid_0's auc: 0.857082\n",
      "[1200]\tvalid_0's auc: 0.857136\n",
      "[1400]\tvalid_0's auc: 0.857176\n",
      "[1600]\tvalid_0's auc: 0.857194\n",
      "[1800]\tvalid_0's auc: 0.857204\n",
      "[2000]\tvalid_0's auc: 0.857212\n",
      "[2200]\tvalid_0's auc: 0.857216\n",
      "[2400]\tvalid_0's auc: 0.85722\n",
      "[2600]\tvalid_0's auc: 0.857225\n",
      "[2800]\tvalid_0's auc: 0.857233\n",
      "[3000]\tvalid_0's auc: 0.857239\n",
      "[3200]\tvalid_0's auc: 0.857246\n",
      "[3400]\tvalid_0's auc: 0.857252\n",
      "[3600]\tvalid_0's auc: 0.857258\n",
      "[3800]\tvalid_0's auc: 0.857264\n",
      "[4000]\tvalid_0's auc: 0.85727\n",
      "[4200]\tvalid_0's auc: 0.857278\n",
      "[4400]\tvalid_0's auc: 0.857284\n",
      "[4600]\tvalid_0's auc: 0.857289\n",
      "[4800]\tvalid_0's auc: 0.857297\n",
      "[5000]\tvalid_0's auc: 0.857305\n",
      "[5200]\tvalid_0's auc: 0.857315\n",
      "[5400]\tvalid_0's auc: 0.857324\n",
      "[5600]\tvalid_0's auc: 0.85733\n",
      "[5800]\tvalid_0's auc: 0.857337\n",
      "[6000]\tvalid_0's auc: 0.857344\n",
      "[6200]\tvalid_0's auc: 0.857349\n",
      "[6400]\tvalid_0's auc: 0.857355\n",
      "[6600]\tvalid_0's auc: 0.85736\n",
      "[6800]\tvalid_0's auc: 0.857362\n",
      "[7000]\tvalid_0's auc: 0.857367\n",
      "[7200]\tvalid_0's auc: 0.85737\n",
      "[7400]\tvalid_0's auc: 0.857372\n",
      "[7600]\tvalid_0's auc: 0.857374\n",
      "[7800]\tvalid_0's auc: 0.857374\n",
      "[8000]\tvalid_0's auc: 0.857375\n",
      "[8200]\tvalid_0's auc: 0.857375\n",
      "[8400]\tvalid_0's auc: 0.857373\n",
      "[8600]\tvalid_0's auc: 0.857373\n",
      "[8800]\tvalid_0's auc: 0.857371\n",
      "Early stopping, best iteration is:\n",
      "[8164]\tvalid_0's auc: 0.857376\n",
      "Fold: 4 Model: lgbm0 Score: 0.8573759648050453 Duration : 0:23:22.656139\n",
      "Average Validation Score | lgbm0: 0.857039506808472\n",
      "CPU times: user 6h 59min 8s, sys: 2min 56s, total: 7h 2min 5s\n",
      "Wall time: 1h 53min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Moving onto the time killer section\n",
    "models = [\n",
    "#     (\"lgbm3\", LGBMClassifier(**lgbm_params_3)),\n",
    "    (\"lgbm0\", LGBMClassifier(**lgbm_params_0)),\n",
    "#     (\"lgbm0a\", LGBMClassifier(**lgbm_params_0a)),\n",
    "#     (\"lgbm0b\", LGBMClassifier(**lgbm_params_0b)),\n",
    "#     (\"lgbm0c\", LGBMClassifier(**lgbm_params_0c)),\n",
    "#     (\"lgbm1\", LGBMClassifier(**lgbm_params_1)),\n",
    "#     (\"lgbm1a\", LGBMClassifier(**lgbm_params_1a)),\n",
    "#     (\"lgbm1b\", LGBMClassifier(**lgbm_params_1b)),\n",
    "#     (\"lgbm1c\", LGBMClassifier(**lgbm_params_1c)),\n",
    "#    (\"lgbm1\", LGBMClassifier(**lgbm_params_1)),\n",
    "#    (\"lgbm1\", LGBMClassifier(**lgbm_params_1)),\n",
    "#     (\"catb0\", CatBoostClassifier(**catb_params_0)),\n",
    "#     (\"catb1\", CatBoostClassifier(**catb_params_1)),\n",
    "#     (\"xgb0\", XGBClassifier(**xgb_params_0)),\n",
    "#     (\"xgb1\", XGBClassifier(**xgb_params_1)),\n",
    "]\n",
    "\n",
    "oof_pred_tmp = dict()\n",
    "test_pred_tmp = dict()\n",
    "scores_tmp = dict()\n",
    "\n",
    "### Another new addition so that I can see FI\n",
    "mod_importances = pd.DataFrame()\n",
    "\n",
    "print (\"Start time :\", datetime.now() )\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "for fold, (idx_train, idx_valid) in enumerate(kf.split(X, y)):\n",
    "    print (\"Fold : \", fold, \" Start : \", datetime.now())\n",
    "    X_train, y_train = X.iloc[idx_train], y.iloc[idx_train]\n",
    "    X_valid, y_valid = X.iloc[idx_valid], y.iloc[idx_valid]\n",
    "\n",
    "\n",
    "    for name, model in models:\n",
    "        start_time = datetime.now()\n",
    "        print (\"model name : \", name, \" Start : \", datetime.now())\n",
    "        if name not in scores_tmp:\n",
    "            oof_pred_tmp[name] = list()\n",
    "            oof_pred_tmp[\"y_valid\"] = list()\n",
    "            test_pred_tmp[name] = list()\n",
    "            scores_tmp[name] = list()\n",
    "\n",
    "        if name.startswith(\"lgbm0\"):\n",
    "            print (\"Name starts with lgbm0\")\n",
    "     \n",
    "            # I think that I will need to go much lower with my new features\n",
    "            lgb_params['learning_rate'] = 0.003\n",
    "            model = LGBMClassifier(**lgb_params)\n",
    "            model.fit( X_train, y_train,\n",
    "                eval_set=[(X_valid,y_valid)],\n",
    "                eval_metric='auc',\n",
    "                early_stopping_rounds=700,        \n",
    "                verbose=200,\n",
    "            )\n",
    "            \n",
    "            ### messing about with second fits is not needed\n",
    "            ### I was just messing about with it since I hadn't tried it before. \n",
    "            ### Can't say that I was overly impressed\n",
    "            \n",
    "            \n",
    "        \n",
    "        elif name.startswith(\"xgb0\"):\n",
    "            print (\"Name starts with xgb0\")\n",
    "            \n",
    "            xgb_params_0['learning_rate'] = 0.02\n",
    "            pre_model = XGBClassifier(**xgb_params_0)\n",
    "            pre_model.fit( X_train, y_train,\n",
    "                eval_set=[(X_valid,y_valid)],\n",
    "                eval_metric='auc',\n",
    "                early_stopping_rounds=700,        \n",
    "                verbose=1000,\n",
    "            )\n",
    "            \n",
    "            xgb_params_0['learning_rate'] *= 0.1\n",
    "            model = XGBClassifier(**xgb_params_0)\n",
    "            model.fit(X_train, y_train,\n",
    "                    eval_set=[(X_valid,y_valid)],\n",
    "                    eval_metric='auc',\n",
    "                    early_stopping_rounds=500,\n",
    "                    verbose=200,\n",
    "                    xgb_model=pre_model)\n",
    "            \n",
    "        elif name.startswith(\"catb0\"):\n",
    "            print (\"Name starts with catb0\")\n",
    "            ### catboost doens't like a boolean target \n",
    "            y_train = y_train.astype('float')\n",
    "            y_valid = y_valid.astype('float')\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid,y_valid)],\n",
    "                early_stopping_rounds=500,\n",
    "                verbose=1000)\n",
    "            \n",
    "                \n",
    "        else:\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid,y_valid)],\n",
    "                early_stopping_rounds=500,\n",
    "                verbose=1000\n",
    "            )\n",
    "        ## end if\n",
    "        \n",
    "        # Can't recall where I nicked this, but it is useful\n",
    "        fi_tmp = pd.DataFrame()\n",
    "        fi_tmp['feature'] = X_train.columns\n",
    "        fi_tmp['importance'] = model.feature_importances_\n",
    "        fi_tmp['fold'] = fold\n",
    "        fi_tmp['seed'] = 42    ## seed value within params\n",
    "        mod_importances = mod_importances.append(fi_tmp)\n",
    "        \n",
    "        ## This FI code is really handy. It can also be used for handling lopps of seeds as well.\n",
    "        ## Good practice for LB climbing but overkill for a sandpit\n",
    "    \n",
    "        ### Time to get the predictions for oof test data (valid data)\n",
    "        pred_valid = model.predict_proba(X_valid)[:, -1]\n",
    "        score = roc_auc_score(y_valid, pred_valid)\n",
    "        \n",
    "        scores_tmp[name].append(score)\n",
    "        oof_pred_tmp[name].extend(pred_valid)\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        f_pred.loc[idx_valid, 'pred'] = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        print(f\"Fold: {fold} Model: {name} Score: {score}\", \"Duration :\", duration)\n",
    "\n",
    "        ### Time to get the predictions for competition test data (df_test descendandts)\n",
    "        y_hat = model.predict_proba(test_data)[:,1]\n",
    "        test_pred_tmp[name].append(y_hat)\n",
    "        \n",
    "    oof_pred_tmp[\"y_valid\"].extend(y_valid)\n",
    "        \n",
    "        \n",
    "for name, model in models:\n",
    "    print(f\"Average Validation Score | {name}: {np.mean(scores_tmp[name])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5662de2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T23:44:14.096726Z",
     "iopub.status.busy": "2021-10-29T23:44:14.095857Z",
     "iopub.status.idle": "2021-10-29T23:44:18.221090Z",
     "shell.execute_reply": "2021-10-29T23:44:18.221720Z",
     "shell.execute_reply.started": "2021-10-29T21:45:47.221732Z"
    },
    "papermill": {
     "duration": 4.228504,
     "end_time": "2021-10-29T23:44:18.221938",
     "exception": false,
     "start_time": "2021-10-29T23:44:13.993434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_pred.to_csv(\"./f_pred_train.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd98a71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T23:44:18.418794Z",
     "iopub.status.busy": "2021-10-29T23:44:18.418094Z",
     "iopub.status.idle": "2021-10-29T23:44:22.126837Z",
     "shell.execute_reply": "2021-10-29T23:44:22.127684Z",
     "shell.execute_reply.started": "2021-10-29T21:45:49.961719Z"
    },
    "papermill": {
     "duration": 3.812516,
     "end_time": "2021-10-29T23:44:22.127936",
     "exception": false,
     "start_time": "2021-10-29T23:44:18.315420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Time to unravel those dictionaries of models and predictions \n",
    "test_predictions = pd.DataFrame(  \n",
    "    {name: np.mean(np.column_stack(test_pred_tmp[name]), axis=1) for name in test_pred_tmp.keys()}\n",
    ")\n",
    "\n",
    "# Always handy to save a copy for use later\n",
    "test_predictions.to_csv(\"./test_predictions.csv\", index=False)\n",
    "\n",
    "# get the average of all predictions\n",
    "test_predictions[\"avg\"] = test_predictions.mean(axis=1)\n",
    "\n",
    "# overwrite target in sample_submission with our new and improved predictions \n",
    "avg_submission = sample_submission.copy()\n",
    "avg_submission[\"target\"] = test_predictions[\"avg\"]\n",
    "avg_submission.to_csv(\"./avg_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92358f60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T23:44:22.346051Z",
     "iopub.status.busy": "2021-10-29T23:44:22.345025Z",
     "iopub.status.idle": "2021-10-29T23:44:25.034524Z",
     "shell.execute_reply": "2021-10-29T23:44:25.035086Z",
     "shell.execute_reply.started": "2021-10-29T21:45:50.064460Z"
    },
    "papermill": {
     "duration": 2.794068,
     "end_time": "2021-10-29T23:44:25.035278",
     "exception": false,
     "start_time": "2021-10-29T23:44:22.241210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_pred_test = sample_submission.copy()\n",
    "f_pred_test['pred'] = test_predictions[\"avg\"]\n",
    "f_pred_test.to_csv(\"./f_pred_test.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "155a577a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T23:44:25.538349Z",
     "iopub.status.busy": "2021-10-29T23:44:25.537641Z",
     "iopub.status.idle": "2021-10-29T23:44:30.117280Z",
     "shell.execute_reply": "2021-10-29T23:44:30.118014Z",
     "shell.execute_reply.started": "2021-10-29T21:45:50.065768Z"
    },
    "papermill": {
     "duration": 4.984671,
     "end_time": "2021-10-29T23:44:30.118258",
     "exception": false,
     "start_time": "2021-10-29T23:44:25.133587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Training Validation Score | Blend: 0.8570229381328826\n"
     ]
    }
   ],
   "source": [
    "# So that oof_pred_tmp dictionary that we populated during training was so that\n",
    "# we can get the real validation score across the whole training dataset and not just avergae \n",
    "# individual folds. I have once before started a discussion within the competition detailing the \n",
    "# importance of this step\n",
    "\n",
    "oof_predictions = pd.DataFrame({name:oof_pred_tmp[name] for name in oof_pred_tmp.keys()})\n",
    "\n",
    "# Again Always handy so save a copy for revisiting\n",
    "oof_predictions.to_csv(\"./oof_preds.csv\", index=False)\n",
    "\n",
    "# And now we get the all important validation score\n",
    "y_valid = oof_predictions[\"y_valid\"].copy()\n",
    "y_hat_blend = oof_predictions.drop(columns=[\"y_valid\"]).mean(axis=1)\n",
    "score = roc_auc_score(y_valid, y_hat_blend)\n",
    "\n",
    "print(f\"Overall Training Validation Score | Blend: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce151881",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T23:44:30.310275Z",
     "iopub.status.busy": "2021-10-29T23:44:30.309566Z",
     "iopub.status.idle": "2021-10-29T23:44:31.228363Z",
     "shell.execute_reply": "2021-10-29T23:44:31.228899Z",
     "shell.execute_reply.started": "2021-10-29T21:45:50.067227Z"
    },
    "papermill": {
     "duration": 1.017024,
     "end_time": "2021-10-29T23:44:31.229105",
     "exception": false,
     "start_time": "2021-10-29T23:44:30.212081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LGB feature importances')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "order = list(mod_importances.groupby('feature').mean().sort_values('importance', ascending=False).index)\n",
    "\n",
    "## I want the graph to be readable\n",
    "for i in range(250):\n",
    "    order.pop()\n",
    "## Half embarrassed to put out such lazy code - but be fair ... it is doing the job I want it to.\n",
    "\n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize=(16, 16), tight_layout=True)\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=mod_importances.groupby('feature').mean().reset_index(), order=order)\n",
    "plt.title(\"LGB feature importances\")\n",
    "\n",
    "#  From the original sandpit notebook we see \n",
    "#Results tracking\n",
    "# V3 LGBM0 Overall Training Validation Score | Blend: 0.8569692225223414 with LB score of 0.85633\n",
    "# V4 LGBM0 Overall Training Validation Score | Blend: 0.8570320102774184 with LB score of 0.85623\n",
    "# V5 LGBM0 Overall Training Validation Score | Blend: 0.8570190414332162 with LB score of 0.85627\n",
    "# V6 LGBM1 Overall Training Validation Score | Blend: 0.8571127311293687 with LB score of 0.85633\n",
    "# V7 XGB0 Overall Training Validation Score | Blend: 0.8570048237818386 with LB score of 0.85645\n",
    "# V8 XGB1 Overall Training Validation Score | Blend: 0.8568621253215738 with LB score of 0.85621\n",
    "# V10 CATB0 Overall Training Validation Score | Blend: 0.8566436011399643 with LB score of 0.85597\n",
    "# V11 LGBM0 Overall Training Validation Score | Blend: 0.8569640619014858 with LB score of 0.85638\n",
    "\n",
    "\n",
    "# When Running the LGB model the best feature is the xgb output \n",
    "# What does that tell us?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0209cd8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-29T23:44:31.425873Z",
     "iopub.status.busy": "2021-10-29T23:44:31.424737Z",
     "iopub.status.idle": "2021-10-29T23:44:31.449833Z",
     "shell.execute_reply": "2021-10-29T23:44:31.450640Z",
     "shell.execute_reply.started": "2021-10-29T21:45:50.068420Z"
    },
    "papermill": {
     "duration": 0.125971,
     "end_time": "2021-10-29T23:44:31.450919",
     "exception": false,
     "start_time": "2021-10-29T23:44:31.324948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            pred\n",
      "0       0.575506\n",
      "1       0.195429\n",
      "2       0.813035\n",
      "3       0.485040\n",
      "4       0.804777\n",
      "...          ...\n",
      "999995  0.717001\n",
      "999996  0.129997\n",
      "999997  0.200207\n",
      "999998  0.937422\n",
      "999999  0.543893\n",
      "\n",
      "[1000000 rows x 1 columns]\n",
      "              v7       v10       v11\n",
      "0       0.627991  0.590088  0.644283\n",
      "1       0.204292  0.161027  0.177315\n",
      "2       0.842159  0.848305  0.833164\n",
      "3       0.509823  0.477536  0.532462\n",
      "4       0.847930  0.826900  0.834583\n",
      "...          ...       ...       ...\n",
      "999995  0.705724  0.820989  0.764636\n",
      "999996  0.121882  0.133618  0.122352\n",
      "999997  0.179142  0.172238  0.175019\n",
      "999998  0.912751  0.899962  0.900747\n",
      "999999  0.584213  0.582276  0.579980\n",
      "\n",
      "[1000000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (f_pred)\n",
    "print (X[['v7', 'v10', 'v11']])\n",
    "\n",
    "### So why do I look here ?\n",
    "\n",
    "# Well I'm only looking at row 0 to start. The original models had predictions of 0.62, 0.59 and 0.64\n",
    "# Averaging, ensembling, stacking (whatever you want to call that) would normally give a new prediction here of around 0.62\n",
    "# My new prediction is 0.57\n",
    "# Now for each row - new results are always closer to 0.5 regardless of direction. Statistically speaking f_pred has lower variance\n",
    "\n",
    "# So my new results are still the same in 'classification' but they are less confident\n",
    "\n",
    "# Could we add this new feature into the next version and just keep looping?\n",
    "# Would pred end up being 1 million rows of 0.5\n",
    "# Would it help throwing this through a Scaler ?\n",
    "# Will the stccking benefit of this output be less helpful to the leaderboard?\n",
    "\n",
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7106.52089,
   "end_time": "2021-10-29T23:44:34.550539",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-29T21:46:08.029649",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
